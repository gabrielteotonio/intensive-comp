---
title: "Report"
author: "Gabriel Teotonio"
date: "9/28/2020"
output: html_document
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

devtools::load_all(".")
```

![](image_report.png)

## Introduction
In linear algebra we are concerned about linear equations such as:  
$$a_1x_1 + \dots + a_nx_n = b, $$
and their representations through matrices. When we talk about machine learning algorithms, most of them have linear algebra and matrix calculation in its core, e.g. regression when is necessary to find the solution of $Y = X B + \varepsilon$, neural nets needs to execute a number of matrix product operations for each layer considered, and others.  
With this in mind I implemented a variety of algorithms to analyze the performance of processing it, in relation to speed. Multiple approaches are considered, including C++ [Armadillo](http://arma.sourceforge.net/docs.html) library and different parallel back-ends.  The following R package named **matrixProduct** gathers all the development. The **microbenchmark**, **ggplot2**, and **pryr** packages will help us to measure that performance.

```{r setup, message=FALSE, warning=FALSE}
library(matrixProduct)
library(microbenchmark)
library(pryr)
library(ggplot2)
library(readr)
library(dplyr)
```


## Approaches
Here I consider two possible ways: lower-level and parallelism way. So we can build our code in a faster language than R, like C++, try to parallelize  the code in R or even both.

### Lower-level way 
The initial attempt is to measure the performance of base operators for matrix multiplication in R and C++. We know the command `%*%` in R to execute the multiplication and its optimized implementation throughout the years. We also consider the base matrix multiplication command in C++ library Armadillo `*`. To integrate Armadillo to R, let's use R package [RcppArmadillo](https://cran.r-project.org/web/packages/RcppArmadillo/index.html). We are going to build some simple functions only for calling the base commands of each library. The integration between C++ and R with Rcpp is seamless and simple to get started (all the code can be found [here](https://github.com/gabrielteotonio/intensive-comp)).

#### Versions  {.tabset}
##### No garbage collector
```{r lower, echo=TRUE, message=FALSE, fig.width=6, fig.height=4, eval=FALSE}
trials <- 10000
mat_size <- 3

for (i in 1:trials) {
  
   mat_1 <- list(matrix(runif(100, 0, 1), 10, 10),
                 matrix(runif(10000, 0, 1), 100, 100),
                 matrix(runif(1000000, 0, 1), 1000, 1000)
                )
   mat_2 <- list(matrix(runif(100, 0, 1), 10, 10),
                 matrix(runif(10000, 0, 1), 100, 100),
                 matrix(runif(1000000, 0, 1), 1000, 1000)
                )
  
  for (j in 1:mat_size) {
    res <- data.frame(expr = character(0), 
                      time = numeric(0),
                      trial = numeric(0),
                      mat_size = numeric(0),
                      memory_used = numeric(0))
    
    res <- microbenchmark(Rbase = mat_1[[j]] %*% mat_2[[j]],
                          ArmadilloBase = matrixProduct::ArmaBase(mat_1[[j]], mat_2[[j]]),
                          ArmadilloIterator = matrixProduct::ArmaColumnRow(mat_1[[j]], mat_2[[j]]),
                          times = 1
                         )
    res$trial <- i
    res$mat_size <- j
    res$memory_used <- mem_used()
    
    write.table(res, "results/results_seq.csv", sep = ",", col.names = !file.exists("results/results_seq.csv"), append = TRUE, row.names = FALSE)
    
    rm(res)
    
  }
  
  rm(mat_1, mat_2)
  
}
```

##### Within garbage collector
```{r lower_gc, echo=TRUE, message=FALSE, fig.width=6, fig.height=4, eval=FALSE}
trials <- 10000
mat_size <- c(100, 10000, 1000000)
mat_dim <- c(10, 100, 1000)

for (i in 1:length(mat_size)) {
  res <- data.frame(expr = character(0), 
                    time = numeric(0),
                    trial = numeric(0),
                    size = numeric(0),
                    memory_used = numeric(0))  
   
  for (j in 1:trials) {

    mat_1 <- matrix(runif(mat_size[i], 0, 1), mat_dim[i], mat_dim[i])
    mat_2 <- matrix(runif(mat_size[i], 0, 1), mat_dim[i], mat_dim[i])
    
    bench <- microbenchmark(Rbase = mat_1 %*% mat_2,
                            ArmadilloBase = matrixProduct::ArmaBase(mat_1, mat_2),
                            ArmadilloIterator = matrixProduct::ArmaColumnRow(mat_1, mat_2),
                            times = 1
                           )
    bench$trial <- j
    bench$mat_size <- i
    bench$memory_used <- mem_used()
    
    res <- rbind(res, bench)
    
    rm(mat_1, mat_2)
    
  }
  
  write.table(res, "results/results_seq_gc.csv", sep = ",", col.names = !file.exists("results/results_seq_gc.csv"), append = TRUE, row.names = FALSE)
    
  rm(res)
  invisible(gc())
  
}
```


### Parallelism way
Now we consider different parallel backends to compute the multiplication operation. Deal with parallel processing require from us an good understanding about what our code does exactly and how it can be improved. Different from how people think in general, parallelize a process not necessarily improves its time consuming in a linear way: double the number of processors should halve the time required to execute that process. Because of it, it's so important understand which parts of your code could speedup your process once parallelized. In our case, we can break this multiplication in into columns and lines operations, and decided which one would be send to a parallel backend.

#### Versions {.tabset}
##### No garbage collector
```{r parallel, echo=TRUE, message=FALSE, fig.width=6, fig.height=4, eval=FALSE}
trials_par <- 10
mat_size <- 3
niter <- 8

for (i in 1:trials_par) {
  
   mat_1 <- list(matrix(runif(100, 0, 1), 10, 10),
                 matrix(runif(100, 0, 1), 10, 10),
                 matrix(runif(100, 0, 1), 10, 10)
                )
   mat_2 <- list(matrix(runif(100, 0, 1), 10, 10),
                 matrix(runif(100, 0, 1), 10, 10),
                 matrix(runif(100, 0, 1), 10, 10)
                )
  
  for (j in 1:mat_size) {
    res <- data.frame(expr = character(0), 
                      time = numeric(0),
                      trial = numeric(0),
                      mat_size = numeric(0),
                      memory_used = numeric(0))
    
    res <- microbenchmark(RparallelRow = matrixProduct::ParallelRow(mat_1[[j]], mat_2[[j]], niter),
                          RparallelColumn = matrixProduct::ParallelColumn(mat_1[[j]], mat_2[[j]], niter),
                          RcppParallel = matrixProduct::RcppParallel(mat_1[[j]], t(mat_2[[j]]), niter),
                          RcppOpenMP = matrixProduct::RcppOpenMP(mat_1[[j]], mat_2[[j]], niter),
                          times = 1
                         )
    res$trial <- i
    res$mat_size <- j
    res$memory_used <- mem_used()
    
    write.table(res, "results/results_par.csv", sep = ",", col.names = !file.exists("results/results_par.csv"), append = TRUE, row.names = FALSE)
    
    rm(res)
    
  }
  
  rm(mat_1, mat_2)
  
}
```

##### Within garbage collector
```{r parallel_gc, echo=TRUE, message=FALSE, fig.width=6, fig.height=4, eval=FALSE}
trials_par <- 100
mat_size <- c(100, 10000, 1000000)
mat_dim <- c(10, 100, 1000)
niter <- 8

for (i in 1:length(mat_size)) {
  res <- data.frame(expr = character(0), 
                    time = numeric(0),
                    trial = numeric(0),
                    mat_size = numeric(0),
                    memory_used = numeric(0))
  
  for (j in 1:trials_par) {
    
    mat_1 <- matrix(runif(mat_size[i], 0, 1), mat_dim[i], mat_dim[i])
    mat_2 <- matrix(runif(mat_size[i], 0, 1), mat_dim[i], mat_dim[i])
    
    bench <- microbenchmark(RparallelRow = matrixProduct::ParallelRow(mat_1, mat_2, niter),
                            RparallelColumn = matrixProduct::ParallelColumn(mat_1, mat_2, niter),
                            RcppParallel = matrixProduct::RcppParallel(mat_1, t(mat_2), niter),
                            RcppOpenMP = matrixProduct::RcppOpenMP(mat_1, mat_2, niter),
                            times = 1
                           )
    
    bench$trial <- j
    bench$mat_size <- i
    bench$memory_used <- mem_used()
    
    res <- rbind(res, bench)
    
    rm(mat_1, mat_2)
    
  }
  
  write.table(res, "results/results_par_gc.csv", sep = ",", col.names = !file.exists("results/results_par_gc.csv"), append = TRUE, row.names = FALSE)
  
  rm(res)
  invisible(gc())
  
}
```


### Results 

```{r results, echo=FALSE, warning=FALSE, message=FALSE}
results_seq <- read_csv("results/results_seq.csv") %>% 
  mutate(run = "seq") %>% 
  mutate(memory_used = memory_used/min(memory_used)) %>% 
  mutate(approach = "seq")
results_seq_gc <- read_csv("results/results_seq_gc.csv") %>% 
  mutate(run = "seq_gc") %>% 
  mutate(memory_used = memory_used/min(memory_used)) %>% 
  mutate(approach = "seq")

results_par <- read_csv("results/results_par.csv") %>% 
  mutate(run = "par") %>% 
  mutate(memory_used = memory_used/min(memory_used)) %>% 
  mutate(approach = "par")
results_par_gc <- read_csv("results/results_par_gc.csv") %>% 
  mutate(run = "par_gc") %>% 
  mutate(memory_used = memory_used/min(memory_used)) %>% 
  mutate(approach = "par")

results_sequential <- union(results_seq, results_seq_gc)
results_parallel <- union(results_par, results_par_gc)

results <- union(results_sequential, results_parallel) %>% 
  mutate(trial = as.character(trial), mat_size = as.character(mat_size)) %>% 
  mutate(time = log(time)) 
```

We have the following results. We consider 8 processors to run the experiments in parallel. On the left plot we can see the comparison among all the methods, combining garbage collector or no. The Rbase method achieved the smallest median, being its no gc version a little bit better. Even the RcppOpenMP and RcppParallel methods failing to achieve the performance of Rbase, its variance are smaller and this may suggest that they can be useful in some scenarios.  Also we can see that forces R to execute garbage collector may insert overhead in our calculation. In the second plot its possible to compare sequential and parallel processes. The distribution of each one has different aspects. For parallel, we have a distribution with a positive assymetry, while the sequential version has a negative one. However, their 3rd-quantile are, approximately, equal.


```{r plots_1, echo=FALSE, warning=FALSE, message=FALSE, fig.height=3, fig.width=4.7}
p <- results %>% 
  ggplot(aes(x=expr, y=time, fill=run)) +
  geom_boxplot() +
  labs(x="Method", y="Time", fill = "Run") + 
  theme(axis.text.x = element_text(angle = 65))

q <- results %>% 
  ggplot(aes(x=approach, y=time, fill=approach)) +
  geom_boxplot() +
  labs(x="Approach", y="Time") + 
  theme(axis.text.x = element_text(angle = 65))


p
q
```



The memory used by R to execute ou simulation is also affected by the version within garbage collector. On the left we have a scatter plot of memory used (above the min) and time required to run. The observations in `seq_gc` and `par_gc` required more memory to run the simulation. In particular, some observations of `seq_gc` used 20% more memory than its version without gc.
```{r plots_2, echo=FALSE, warning=FALSE, message=FALSE, fig.height=3, fig.width=4.7}
p <- results %>% 
  ggplot(aes(x=memory_used, y=time, color=run)) +
  geom_point() + 
  labs(x="Memory used", y="Time")



q <- results %>% 
  ggplot(aes(x=mat_size, y=time, fill=approach)) +
  geom_boxplot() +
  labs(x="Matrix size", y="Time") + 
  theme(axis.text.x = element_text(angle = 65))

p
q
```
